{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "SAMPLES_PER_EPOCH = 50000\n",
    "EPOCH_NUM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def conv_layer(input, shape):\n",
    "    W = weight_variable(shape)\n",
    "    b = bias_variable([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input, W) + b)\n",
    "\n",
    "\n",
    "def full_layer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = weight_variable([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b\n",
    "  \n",
    "def get_batch(features,labels,batch_size): \n",
    "    num_images = features.shape[0]\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=batch_size,\n",
    "                           replace=False)\n",
    "    features_batch = features[idx, :, :, :]\n",
    "    labels_batch = labels[idx, :]\n",
    "    return features_batch, labels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
    "\n",
    "num_train, img_rows, img_cols, img_channels =  train_features.shape\n",
    "num_test =  test_features.shape[0]\n",
    "num_classes = np.unique(train_labels).shape[0]\n",
    "\n",
    "train_features = train_features.astype('float32')/np.max(train_features)\n",
    "test_features = test_features.astype('float32')/np.max(test_features)\n",
    "\n",
    "\n",
    "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = np_utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "print(train_features.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32 , shape=[None , img_rows,img_cols,img_channels]) \n",
    "y_ = tf.placeholder(tf.float32 , shape=[None, 10]) \n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "test_features, test_labels = get_batch(test_features,test_labels,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('conv_1'): \n",
    "    conv1 = conv_layer(x , shape=[3, 3, img_channels, 64])\n",
    "    conv1_pool = max_pool_2x2( conv1 )\n",
    "\n",
    "with tf.name_scope('conv_2'): \n",
    "    conv2 = conv_layer(conv1_pool , shape=[3, 3, 64, 128])\n",
    "    conv2_pool = max_pool_2x2 ( conv2 )\n",
    "\n",
    "with tf.name_scope('conv_3'): \n",
    "    conv3 = conv_layer(conv2_pool , shape=[3, 3, 128, 256] )\n",
    "    conv3_pool = max_pool_2x2 ( conv3 )\n",
    "    conv3_flat = tf.contrib.layers.flatten(conv3_pool) \n",
    "\n",
    "with tf.name_scope('full_1'): \n",
    "    full_1 = tf.nn.relu(full_layer(conv3_flat , 512))\n",
    "\n",
    "with tf.name_scope('dropout'): \n",
    "    full1_drop = tf.nn.dropout(full_1 , keep_prob=keep_prob) \n",
    "\n",
    "with tf.name_scope('activations'): \n",
    "    y_conv = full_layer(full1_drop , 10) \n",
    "    tf.summary.scalar('cross_entropy_loss',y_conv)\t\n",
    "\n",
    "with tf.name_scope('cross'): \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_conv , labels=y_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 32, 32, 3) (500, 10)\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.AdagradOptimizer(1e-3).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv , 1), tf.argmax(y_, 1)) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction , tf.float32))\n",
    "print(test_features.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 11.12755036354065, epoch 0, training accuracy 0.3125\n",
      "time 22.256116151809692, epoch 1, training accuracy 0.375\n",
      "time 33.27667212486267, epoch 2, training accuracy 0.4375\n",
      "time 44.32392978668213, epoch 3, training accuracy 0.59375\n",
      "time 55.36373996734619, epoch 4, training accuracy 0.375\n",
      "time 66.40747284889221, epoch 5, training accuracy 0.40625\n",
      "time 77.45854163169861, epoch 6, training accuracy 0.5\n",
      "time 88.50820446014404, epoch 7, training accuracy 0.65625\n",
      "time 99.59323906898499, epoch 8, training accuracy 0.53125\n",
      "time 110.69370675086975, epoch 9, training accuracy 0.4375\n",
      "time 121.82086753845215, epoch 10, training accuracy 0.5\n",
      "time 133.1295759677887, epoch 11, training accuracy 0.4375\n",
      "time 144.22264432907104, epoch 12, training accuracy 0.5625\n",
      "time 155.30719208717346, epoch 13, training accuracy 0.375\n",
      "time 166.39895725250244, epoch 14, training accuracy 0.4375\n",
      "time 177.53019666671753, epoch 15, training accuracy 0.5\n",
      "time 188.66424417495728, epoch 16, training accuracy 0.4375\n",
      "time 199.84884810447693, epoch 17, training accuracy 0.46875\n",
      "time 211.00731897354126, epoch 18, training accuracy 0.625\n",
      "time 222.20175313949585, epoch 19, training accuracy 0.375\n",
      "time 233.31018328666687, epoch 20, training accuracy 0.5\n",
      "time 244.4594283103943, epoch 21, training accuracy 0.46875\n",
      "time 256.7353229522705, epoch 22, training accuracy 0.46875\n",
      "time 268.42008900642395, epoch 23, training accuracy 0.5\n",
      "time 280.0863609313965, epoch 24, training accuracy 0.59375\n",
      "time 291.89555311203003, epoch 25, training accuracy 0.5\n",
      "time 303.5143926143646, epoch 26, training accuracy 0.625\n",
      "time 315.2483787536621, epoch 27, training accuracy 0.625\n",
      "time 326.9459385871887, epoch 28, training accuracy 0.34375\n",
      "time 338.5464096069336, epoch 29, training accuracy 0.5625\n",
      "time 350.2288851737976, epoch 30, training accuracy 0.71875\n",
      "time 361.8502700328827, epoch 31, training accuracy 0.53125\n",
      "time 373.4424104690552, epoch 32, training accuracy 0.53125\n",
      "time 385.12386894226074, epoch 33, training accuracy 0.5625\n",
      "time 396.7697353363037, epoch 34, training accuracy 0.5625\n",
      "time 408.40182852745056, epoch 35, training accuracy 0.46875\n",
      "time 420.0052101612091, epoch 36, training accuracy 0.46875\n",
      "time 431.62751722335815, epoch 37, training accuracy 0.46875\n",
      "time 443.2149484157562, epoch 38, training accuracy 0.53125\n",
      "time 454.82494020462036, epoch 39, training accuracy 0.40625\n",
      "time 466.3214523792267, epoch 40, training accuracy 0.5\n",
      "time 477.7723307609558, epoch 41, training accuracy 0.5\n",
      "time 489.2133412361145, epoch 42, training accuracy 0.40625\n",
      "time 501.02261447906494, epoch 43, training accuracy 0.53125\n",
      "time 513.0527143478394, epoch 44, training accuracy 0.375\n",
      "time 525.1043765544891, epoch 45, training accuracy 0.53125\n",
      "time 537.0099921226501, epoch 46, training accuracy 0.4375\n",
      "time 548.7199192047119, epoch 47, training accuracy 0.59375\n",
      "time 560.4086079597473, epoch 48, training accuracy 0.625\n",
      "time 572.0034589767456, epoch 49, training accuracy 0.5\n",
      "time 583.5553872585297, epoch 50, training accuracy 0.625\n",
      "time 595.1664080619812, epoch 51, training accuracy 0.53125\n",
      "time 606.755886554718, epoch 52, training accuracy 0.65625\n",
      "time 618.4760231971741, epoch 53, training accuracy 0.5625\n",
      "time 630.1606657505035, epoch 54, training accuracy 0.46875\n",
      "time 641.8534812927246, epoch 55, training accuracy 0.53125\n",
      "time 653.5090312957764, epoch 56, training accuracy 0.625\n",
      "time 665.4324536323547, epoch 57, training accuracy 0.625\n",
      "time 677.1378011703491, epoch 58, training accuracy 0.5625\n",
      "time 688.8129818439484, epoch 59, training accuracy 0.53125\n",
      "time 700.5231130123138, epoch 60, training accuracy 0.53125\n",
      "time 712.2330183982849, epoch 61, training accuracy 0.40625\n",
      "time 723.8939409255981, epoch 62, training accuracy 0.5\n",
      "time 735.7526423931122, epoch 63, training accuracy 0.625\n",
      "time 747.5850088596344, epoch 64, training accuracy 0.53125\n",
      "time 759.216962814331, epoch 65, training accuracy 0.53125\n",
      "time 770.9050667285919, epoch 66, training accuracy 0.5\n",
      "time 782.5259082317352, epoch 67, training accuracy 0.625\n",
      "time 794.14195728302, epoch 68, training accuracy 0.59375\n",
      "time 805.8378720283508, epoch 69, training accuracy 0.53125\n",
      "time 817.4627184867859, epoch 70, training accuracy 0.5625\n",
      "time 829.0582656860352, epoch 71, training accuracy 0.59375\n",
      "time 840.6436455249786, epoch 72, training accuracy 0.625\n",
      "time 852.2376818656921, epoch 73, training accuracy 0.53125\n",
      "time 863.8769733905792, epoch 74, training accuracy 0.65625\n",
      "time 875.5024299621582, epoch 75, training accuracy 0.5\n",
      "time 887.1669595241547, epoch 76, training accuracy 0.4375\n",
      "time 898.730711221695, epoch 77, training accuracy 0.4375\n",
      "time 910.2179548740387, epoch 78, training accuracy 0.53125\n",
      "time 921.8060383796692, epoch 79, training accuracy 0.5\n",
      "time 933.3878693580627, epoch 80, training accuracy 0.53125\n",
      "time 944.978832244873, epoch 81, training accuracy 0.5625\n",
      "time 956.7386021614075, epoch 82, training accuracy 0.65625\n",
      "time 968.3398821353912, epoch 83, training accuracy 0.625\n",
      "time 979.8160169124603, epoch 84, training accuracy 0.59375\n",
      "time 991.375239610672, epoch 85, training accuracy 0.5\n",
      "time 1003.0087962150574, epoch 86, training accuracy 0.75\n",
      "time 1014.4923095703125, epoch 87, training accuracy 0.53125\n",
      "time 1026.1911840438843, epoch 88, training accuracy 0.59375\n",
      "time 1037.7510635852814, epoch 89, training accuracy 0.5625\n",
      "time 1050.1882236003876, epoch 90, training accuracy 0.5625\n",
      "time 1061.9410395622253, epoch 91, training accuracy 0.625\n",
      "time 1073.8742370605469, epoch 92, training accuracy 0.59375\n",
      "time 1085.6122162342072, epoch 93, training accuracy 0.65625\n",
      "time 1097.2089622020721, epoch 94, training accuracy 0.5625\n",
      "time 1108.9193098545074, epoch 95, training accuracy 0.53125\n",
      "time 1120.582855463028, epoch 96, training accuracy 0.5\n",
      "time 1132.3423335552216, epoch 97, training accuracy 0.5\n",
      "time 1143.9347324371338, epoch 98, training accuracy 0.59375\n",
      "time 1155.555006980896, epoch 99, training accuracy 0.5625\n",
      "time 1167.206703901291, epoch 100, training accuracy 0.625\n",
      "time 1178.7708699703217, epoch 101, training accuracy 0.40625\n",
      "time 1190.4029066562653, epoch 102, training accuracy 0.59375\n",
      "time 1201.8900010585785, epoch 103, training accuracy 0.8125\n",
      "time 1213.414278268814, epoch 104, training accuracy 0.59375\n",
      "time 1224.9387273788452, epoch 105, training accuracy 0.5\n",
      "time 1236.3843450546265, epoch 106, training accuracy 0.5625\n",
      "time 1247.8641731739044, epoch 107, training accuracy 0.5625\n",
      "time 1259.2971277236938, epoch 108, training accuracy 0.5625\n",
      "time 1270.7432639598846, epoch 109, training accuracy 0.59375\n",
      "time 1282.3486170768738, epoch 110, training accuracy 0.5\n",
      "time 1293.8944103717804, epoch 111, training accuracy 0.59375\n",
      "time 1305.5032823085785, epoch 112, training accuracy 0.5625\n",
      "time 1316.995169878006, epoch 113, training accuracy 0.625\n",
      "time 1328.5478579998016, epoch 114, training accuracy 0.625\n",
      "time 1340.0809729099274, epoch 115, training accuracy 0.65625\n",
      "time 1351.7024703025818, epoch 116, training accuracy 0.625\n",
      "time 1363.2666418552399, epoch 117, training accuracy 0.5625\n",
      "time 1374.9539864063263, epoch 118, training accuracy 0.40625\n",
      "time 1386.557205915451, epoch 119, training accuracy 0.5\n",
      "time 1398.0659301280975, epoch 120, training accuracy 0.65625\n",
      "time 1409.7678084373474, epoch 121, training accuracy 0.6875\n",
      "time 1421.3431680202484, epoch 122, training accuracy 0.46875\n",
      "time 1433.0571281909943, epoch 123, training accuracy 0.625\n",
      "time 1445.0530154705048, epoch 124, training accuracy 0.5625\n",
      "time 1456.6956903934479, epoch 125, training accuracy 0.46875\n",
      "time 1468.4911098480225, epoch 126, training accuracy 0.59375\n",
      "time 1480.219565629959, epoch 127, training accuracy 0.71875\n",
      "time 1491.9069545269012, epoch 128, training accuracy 0.625\n",
      "time 1503.9966859817505, epoch 129, training accuracy 0.5625\n",
      "time 1515.6876406669617, epoch 130, training accuracy 0.625\n",
      "time 1527.4548451900482, epoch 131, training accuracy 0.5\n",
      "time 1539.0876688957214, epoch 132, training accuracy 0.5625\n",
      "time 1550.6239166259766, epoch 133, training accuracy 0.4375\n",
      "time 1562.3557696342468, epoch 134, training accuracy 0.5625\n",
      "time 1573.9706497192383, epoch 135, training accuracy 0.5\n",
      "time 1585.4911637306213, epoch 136, training accuracy 0.625\n",
      "time 1597.1484541893005, epoch 137, training accuracy 0.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 1608.8126728534698, epoch 138, training accuracy 0.5625\n",
      "time 1620.281985282898, epoch 139, training accuracy 0.46875\n",
      "time 1631.8706374168396, epoch 140, training accuracy 0.5\n",
      "time 1643.433750152588, epoch 141, training accuracy 0.625\n",
      "time 1655.075502872467, epoch 142, training accuracy 0.78125\n",
      "time 1666.6623876094818, epoch 143, training accuracy 0.6875\n",
      "time 1678.2252264022827, epoch 144, training accuracy 0.59375\n",
      "time 1689.8009004592896, epoch 145, training accuracy 0.65625\n",
      "time 1701.4086031913757, epoch 146, training accuracy 0.4375\n",
      "time 1712.966590166092, epoch 147, training accuracy 0.6875\n",
      "time 1724.4713442325592, epoch 148, training accuracy 0.71875\n",
      "time 1735.9155223369598, epoch 149, training accuracy 0.59375\n",
      "time 1747.425496339798, epoch 150, training accuracy 0.4375\n",
      "time 1758.9944779872894, epoch 151, training accuracy 0.53125\n",
      "time 1770.8755168914795, epoch 152, training accuracy 0.625\n",
      "time 1782.3390429019928, epoch 153, training accuracy 0.6875\n",
      "time 1793.8863089084625, epoch 154, training accuracy 0.53125\n",
      "time 1805.320118188858, epoch 155, training accuracy 0.625\n",
      "time 1816.9210126399994, epoch 156, training accuracy 0.59375\n",
      "time 1828.692237854004, epoch 157, training accuracy 0.5625\n",
      "time 1840.2786285877228, epoch 158, training accuracy 0.75\n",
      "time 1851.787578344345, epoch 159, training accuracy 0.46875\n",
      "time 1863.2304859161377, epoch 160, training accuracy 0.5625\n",
      "time 1874.7295672893524, epoch 161, training accuracy 0.5625\n",
      "time 1886.2360603809357, epoch 162, training accuracy 0.5\n",
      "time 1897.752209663391, epoch 163, training accuracy 0.625\n",
      "time 1909.1235885620117, epoch 164, training accuracy 0.5625\n",
      "time 1920.5358309745789, epoch 165, training accuracy 0.40625\n",
      "time 1931.9835937023163, epoch 166, training accuracy 0.59375\n",
      "time 1943.456638097763, epoch 167, training accuracy 0.5625\n",
      "time 1954.9144983291626, epoch 168, training accuracy 0.53125\n",
      "time 1966.3156995773315, epoch 169, training accuracy 0.53125\n",
      "time 1977.8183195590973, epoch 170, training accuracy 0.59375\n",
      "time 1989.2155570983887, epoch 171, training accuracy 0.59375\n",
      "time 2000.7072758674622, epoch 172, training accuracy 0.59375\n",
      "time 2012.207558631897, epoch 173, training accuracy 0.59375\n",
      "time 2023.6709096431732, epoch 174, training accuracy 0.625\n",
      "time 2035.1357791423798, epoch 175, training accuracy 0.71875\n",
      "time 2046.6608095169067, epoch 176, training accuracy 0.6875\n",
      "time 2058.0910284519196, epoch 177, training accuracy 0.59375\n",
      "time 2069.6771943569183, epoch 178, training accuracy 0.625\n",
      "time 2081.301125526428, epoch 179, training accuracy 0.75\n",
      "time 2093.016430616379, epoch 180, training accuracy 0.53125\n",
      "time 2104.4951968193054, epoch 181, training accuracy 0.75\n",
      "time 2116.0140058994293, epoch 182, training accuracy 0.625\n",
      "time 2127.5871045589447, epoch 183, training accuracy 0.65625\n",
      "time 2139.20782995224, epoch 184, training accuracy 0.6875\n",
      "time 2150.7941217422485, epoch 185, training accuracy 0.59375\n",
      "time 2162.4693722724915, epoch 186, training accuracy 0.6875\n",
      "time 2173.9339513778687, epoch 187, training accuracy 0.5625\n",
      "time 2185.426918745041, epoch 188, training accuracy 0.65625\n",
      "time 2197.05570936203, epoch 189, training accuracy 0.5625\n",
      "time 2208.7111344337463, epoch 190, training accuracy 0.5625\n",
      "time 2220.298641681671, epoch 191, training accuracy 0.65625\n",
      "time 2231.962265253067, epoch 192, training accuracy 0.6875\n",
      "time 2243.669761657715, epoch 193, training accuracy 0.625\n",
      "time 2255.3354709148407, epoch 194, training accuracy 0.53125\n",
      "time 2267.0966985225677, epoch 195, training accuracy 0.59375\n",
      "time 2278.839563846588, epoch 196, training accuracy 0.5625\n",
      "time 2290.4162447452545, epoch 197, training accuracy 0.46875\n",
      "time 2301.9905376434326, epoch 198, training accuracy 0.65625\n",
      "time 2313.542689561844, epoch 199, training accuracy 0.53125\n",
      "test accuracy: 0.6119999885559082\n"
     ]
    }
   ],
   "source": [
    " with tf.device(\"/gpu:0\"):   \n",
    "    with tf.Session() as sess: \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for j in range(EPOCH_NUM):\n",
    "            for i in range(SAMPLES_PER_EPOCH // BATCH_SIZE):\n",
    "                batch_trainf, batch_trainl = get_batch(train_features,train_labels,BATCH_SIZE)\n",
    "                sess.run(train_step , feed_dict={x: batch_trainf, y_: batch_trainl, keep_prob: 0.5}) \n",
    "            batch_trainf, batch_trainl = get_batch(test_features,test_labels,32)\n",
    "            train_accuracy = sess.run(accuracy , feed_dict={x: batch_trainf, y_: batch_trainl, keep_prob: 1.0}) \n",
    "            print(\"time {}, epoch {}, training accuracy {}\".format(time.time() - start_time, j, train_accuracy)) \n",
    "\n",
    "        test_accuracy = np.mean([sess.run(accuracy , feed_dict={x:test_features, y_:test_labels, keep_prob:1.0})])\n",
    "        print(\"test accuracy: {}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

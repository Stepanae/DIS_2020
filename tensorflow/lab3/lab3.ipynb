{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "SAMPLES_PER_EPOCH = 50000\n",
    "EPOCH_NUM = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def conv_layer(input, shape):\n",
    "    W = weight_variable(shape)\n",
    "    b = bias_variable([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input, W) + b)\n",
    "\n",
    "\n",
    "def full_layer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = weight_variable([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b\n",
    "  \n",
    "def get_batch(features,labels,batch_size): \n",
    "    num_images = features.shape[0]\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=batch_size,\n",
    "                           replace=False)\n",
    "    features_batch = features[idx, :, :, :]\n",
    "    labels_batch = labels[idx, :]\n",
    "    return features_batch, labels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
    "\n",
    "num_train, img_rows, img_cols, img_channels =  train_features.shape\n",
    "num_test =  test_features.shape[0]\n",
    "num_classes = np.unique(train_labels).shape[0]\n",
    "\n",
    "train_features = train_features.astype('float32')/np.max(train_features)\n",
    "test_features = test_features.astype('float32')/np.max(test_features)\n",
    "\n",
    "\n",
    "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = np_utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "print(train_features.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32 , shape=[None , img_rows,img_cols,img_channels]) \n",
    "y_ = tf.placeholder(tf.float32 , shape=[None, 10]) \n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "test_features, test_labels = get_batch(test_features,test_labels,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('conv_1'): \n",
    "    conv1 = conv_layer(x , shape=[3, 3, img_channels, 64])\n",
    "    conv1_pool = max_pool_2x2( conv1 )\n",
    "\n",
    "with tf.name_scope('conv_2'): \n",
    "    conv2 = conv_layer(conv1_pool , shape=[3, 3, 64, 128])\n",
    "    conv2_pool = max_pool_2x2 ( conv2 )\n",
    "\n",
    "with tf.name_scope('conv_3'): \n",
    "    conv3 = conv_layer(conv2_pool , shape=[3, 3, 128, 256] )\n",
    "    conv3_pool = max_pool_2x2 ( conv3 )\n",
    "    conv3_flat = tf.contrib.layers.flatten(conv3_pool) \n",
    "\n",
    "with tf.name_scope('full_1'): \n",
    "    full_1 = tf.nn.relu(full_layer(conv3_flat , 512))\n",
    "\n",
    "with tf.name_scope('dropout'): \n",
    "    full1_drop = tf.nn.dropout(full_1 , keep_prob=keep_prob) \n",
    "\n",
    "with tf.name_scope('activations'): \n",
    "    y_conv = full_layer(full1_drop , 10) \n",
    "    tf.summary.scalar('cross_entropy_loss',y_conv)\t\n",
    "\n",
    "with tf.name_scope('cross'): \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_conv , labels=y_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 32, 32, 3) (500, 10)\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.AdagradOptimizer(1e-3).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv , 1), tf.argmax(y_, 1)) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction , tf.float32))\n",
    "print(test_features.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 11.172466278076172, epoch 0, training accuracy 0.40625\n",
      "time 22.15634298324585, epoch 1, training accuracy 0.5625\n",
      "time 33.11371684074402, epoch 2, training accuracy 0.375\n",
      "time 44.08511161804199, epoch 3, training accuracy 0.40625\n",
      "time 55.056150913238525, epoch 4, training accuracy 0.40625\n",
      "time 66.04810214042664, epoch 5, training accuracy 0.5\n",
      "time 77.04403734207153, epoch 6, training accuracy 0.34375\n",
      "time 88.06166553497314, epoch 7, training accuracy 0.4375\n",
      "time 99.06902694702148, epoch 8, training accuracy 0.3125\n",
      "time 110.0735695362091, epoch 9, training accuracy 0.5\n",
      "time 121.08499360084534, epoch 10, training accuracy 0.46875\n",
      "time 132.09572005271912, epoch 11, training accuracy 0.375\n",
      "time 143.10369038581848, epoch 12, training accuracy 0.5\n",
      "time 154.10197043418884, epoch 13, training accuracy 0.5\n",
      "time 165.12351536750793, epoch 14, training accuracy 0.5625\n",
      "time 176.14336276054382, epoch 15, training accuracy 0.4375\n",
      "time 187.17725706100464, epoch 16, training accuracy 0.5\n",
      "time 198.19589638710022, epoch 17, training accuracy 0.40625\n",
      "time 209.2246959209442, epoch 18, training accuracy 0.375\n",
      "time 220.260511636734, epoch 19, training accuracy 0.34375\n",
      "time 231.29634356498718, epoch 20, training accuracy 0.625\n",
      "time 242.3327763080597, epoch 21, training accuracy 0.59375\n",
      "time 253.3645055294037, epoch 22, training accuracy 0.46875\n",
      "time 264.4068772792816, epoch 23, training accuracy 0.5\n",
      "time 275.44663310050964, epoch 24, training accuracy 0.375\n",
      "time 286.4983022212982, epoch 25, training accuracy 0.4375\n",
      "time 298.0341944694519, epoch 26, training accuracy 0.375\n",
      "time 309.52403926849365, epoch 27, training accuracy 0.5625\n",
      "time 320.865895986557, epoch 28, training accuracy 0.375\n",
      "time 332.21637058258057, epoch 29, training accuracy 0.4375\n",
      "time 343.6843030452728, epoch 30, training accuracy 0.53125\n",
      "time 355.0942656993866, epoch 31, training accuracy 0.4375\n",
      "time 366.4820840358734, epoch 32, training accuracy 0.34375\n",
      "time 377.92610692977905, epoch 33, training accuracy 0.375\n",
      "time 389.3089876174927, epoch 34, training accuracy 0.53125\n",
      "time 400.6800043582916, epoch 35, training accuracy 0.4375\n",
      "time 412.13195395469666, epoch 36, training accuracy 0.71875\n",
      "time 423.5120131969452, epoch 37, training accuracy 0.5625\n",
      "time 434.837037563324, epoch 38, training accuracy 0.5625\n",
      "time 446.20536732673645, epoch 39, training accuracy 0.59375\n",
      "time 457.5451850891113, epoch 40, training accuracy 0.65625\n",
      "time 468.85325050354004, epoch 41, training accuracy 0.53125\n",
      "time 480.2581367492676, epoch 42, training accuracy 0.4375\n",
      "time 491.6760046482086, epoch 43, training accuracy 0.71875\n",
      "time 503.0390086174011, epoch 44, training accuracy 0.5\n",
      "time 514.3682222366333, epoch 45, training accuracy 0.53125\n",
      "time 525.6489140987396, epoch 46, training accuracy 0.59375\n",
      "time 537.0515270233154, epoch 47, training accuracy 0.46875\n",
      "time 548.4039187431335, epoch 48, training accuracy 0.5\n",
      "time 559.7740840911865, epoch 49, training accuracy 0.53125\n",
      "time 571.1199767589569, epoch 50, training accuracy 0.46875\n",
      "time 582.5050885677338, epoch 51, training accuracy 0.4375\n",
      "time 593.8907175064087, epoch 52, training accuracy 0.5\n",
      "time 605.2956819534302, epoch 53, training accuracy 0.5\n",
      "time 616.7999520301819, epoch 54, training accuracy 0.5625\n",
      "time 628.1814215183258, epoch 55, training accuracy 0.65625\n",
      "time 639.5946385860443, epoch 56, training accuracy 0.625\n",
      "time 650.9105994701385, epoch 57, training accuracy 0.46875\n",
      "time 662.2056729793549, epoch 58, training accuracy 0.46875\n",
      "time 673.6608150005341, epoch 59, training accuracy 0.4375\n",
      "time 684.9482524394989, epoch 60, training accuracy 0.5\n",
      "time 696.4088065624237, epoch 61, training accuracy 0.5\n",
      "time 707.8917410373688, epoch 62, training accuracy 0.59375\n",
      "time 719.3236947059631, epoch 63, training accuracy 0.40625\n",
      "time 730.7621219158173, epoch 64, training accuracy 0.4375\n",
      "time 742.0992705821991, epoch 65, training accuracy 0.5625\n",
      "time 753.6615028381348, epoch 66, training accuracy 0.5\n",
      "time 764.9496984481812, epoch 67, training accuracy 0.625\n",
      "time 776.3743550777435, epoch 68, training accuracy 0.53125\n",
      "time 787.6929924488068, epoch 69, training accuracy 0.46875\n",
      "time 798.9825336933136, epoch 70, training accuracy 0.59375\n",
      "time 810.4357943534851, epoch 71, training accuracy 0.59375\n",
      "time 821.8573286533356, epoch 72, training accuracy 0.625\n",
      "time 833.2847745418549, epoch 73, training accuracy 0.4375\n",
      "time 844.7410109043121, epoch 74, training accuracy 0.59375\n",
      "time 856.1180040836334, epoch 75, training accuracy 0.40625\n",
      "time 867.5509672164917, epoch 76, training accuracy 0.59375\n",
      "time 878.8892996311188, epoch 77, training accuracy 0.59375\n",
      "time 890.4357454776764, epoch 78, training accuracy 0.40625\n",
      "time 901.8618733882904, epoch 79, training accuracy 0.65625\n",
      "time 913.3463370800018, epoch 80, training accuracy 0.5\n",
      "time 924.6823155879974, epoch 81, training accuracy 0.5625\n",
      "time 936.0643985271454, epoch 82, training accuracy 0.40625\n",
      "time 947.4337141513824, epoch 83, training accuracy 0.5\n",
      "time 958.7957673072815, epoch 84, training accuracy 0.59375\n",
      "time 970.2610244750977, epoch 85, training accuracy 0.65625\n",
      "time 981.7078614234924, epoch 86, training accuracy 0.5625\n",
      "time 993.1173439025879, epoch 87, training accuracy 0.46875\n",
      "time 1004.5626044273376, epoch 88, training accuracy 0.53125\n",
      "time 1016.0446126461029, epoch 89, training accuracy 0.65625\n",
      "time 1027.5202977657318, epoch 90, training accuracy 0.5625\n",
      "time 1038.8530712127686, epoch 91, training accuracy 0.65625\n",
      "time 1050.2623944282532, epoch 92, training accuracy 0.59375\n",
      "time 1061.6164190769196, epoch 93, training accuracy 0.5625\n",
      "time 1073.0028371810913, epoch 94, training accuracy 0.6875\n",
      "time 1084.4052481651306, epoch 95, training accuracy 0.65625\n",
      "time 1095.7386765480042, epoch 96, training accuracy 0.59375\n",
      "time 1107.1669099330902, epoch 97, training accuracy 0.59375\n",
      "time 1118.5873427391052, epoch 98, training accuracy 0.53125\n",
      "time 1129.943144083023, epoch 99, training accuracy 0.53125\n",
      "time 1141.3601868152618, epoch 100, training accuracy 0.5625\n",
      "time 1152.8132286071777, epoch 101, training accuracy 0.59375\n",
      "time 1164.2899091243744, epoch 102, training accuracy 0.59375\n",
      "time 1175.5830490589142, epoch 103, training accuracy 0.71875\n",
      "time 1186.8892698287964, epoch 104, training accuracy 0.46875\n",
      "time 1198.1913273334503, epoch 105, training accuracy 0.625\n",
      "time 1209.730993270874, epoch 106, training accuracy 0.5625\n",
      "time 1221.1772501468658, epoch 107, training accuracy 0.53125\n",
      "time 1232.4975612163544, epoch 108, training accuracy 0.4375\n",
      "time 1243.9442162513733, epoch 109, training accuracy 0.4375\n",
      "time 1255.306279182434, epoch 110, training accuracy 0.625\n",
      "time 1266.6355800628662, epoch 111, training accuracy 0.5625\n",
      "time 1278.0191731452942, epoch 112, training accuracy 0.53125\n",
      "time 1289.416347503662, epoch 113, training accuracy 0.6875\n",
      "time 1300.7503185272217, epoch 114, training accuracy 0.65625\n",
      "time 1312.155312538147, epoch 115, training accuracy 0.625\n",
      "time 1323.5431098937988, epoch 116, training accuracy 0.59375\n",
      "time 1334.9966897964478, epoch 117, training accuracy 0.53125\n",
      "time 1346.4006114006042, epoch 118, training accuracy 0.46875\n",
      "time 1357.948059797287, epoch 119, training accuracy 0.6875\n",
      "time 1369.3656778335571, epoch 120, training accuracy 0.5\n",
      "time 1380.772124528885, epoch 121, training accuracy 0.5625\n",
      "time 1392.1696345806122, epoch 122, training accuracy 0.40625\n",
      "time 1403.6331009864807, epoch 123, training accuracy 0.5625\n",
      "time 1415.0587780475616, epoch 124, training accuracy 0.53125\n",
      "time 1426.4959423542023, epoch 125, training accuracy 0.5\n",
      "time 1437.97931432724, epoch 126, training accuracy 0.46875\n",
      "time 1449.3696327209473, epoch 127, training accuracy 0.40625\n",
      "time 1460.8309497833252, epoch 128, training accuracy 0.65625\n",
      "time 1472.2916541099548, epoch 129, training accuracy 0.59375\n",
      "time 1483.698760509491, epoch 130, training accuracy 0.6875\n",
      "time 1495.1266276836395, epoch 131, training accuracy 0.46875\n",
      "time 1506.478502035141, epoch 132, training accuracy 0.65625\n",
      "time 1517.9652230739594, epoch 133, training accuracy 0.71875\n",
      "time 1529.414939403534, epoch 134, training accuracy 0.46875\n",
      "time 1540.9444420337677, epoch 135, training accuracy 0.5625\n",
      "time 1552.4384813308716, epoch 136, training accuracy 0.5625\n",
      "time 1563.8454036712646, epoch 137, training accuracy 0.53125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 1575.1645748615265, epoch 138, training accuracy 0.53125\n",
      "time 1586.6145315170288, epoch 139, training accuracy 0.46875\n",
      "time 1597.975317955017, epoch 140, training accuracy 0.59375\n",
      "time 1609.4048895835876, epoch 141, training accuracy 0.5\n",
      "time 1620.8717620372772, epoch 142, training accuracy 0.71875\n",
      "time 1632.1949820518494, epoch 143, training accuracy 0.53125\n",
      "time 1643.54576253891, epoch 144, training accuracy 0.5\n",
      "time 1655.054877281189, epoch 145, training accuracy 0.65625\n",
      "time 1666.5140256881714, epoch 146, training accuracy 0.625\n",
      "time 1677.9051296710968, epoch 147, training accuracy 0.46875\n",
      "time 1689.4019920825958, epoch 148, training accuracy 0.625\n",
      "time 1700.8471355438232, epoch 149, training accuracy 0.4375\n",
      "time 1712.2862186431885, epoch 150, training accuracy 0.5625\n",
      "time 1723.6990542411804, epoch 151, training accuracy 0.71875\n",
      "time 1735.0588359832764, epoch 152, training accuracy 0.5625\n",
      "time 1746.6235029697418, epoch 153, training accuracy 0.65625\n",
      "time 1758.060703277588, epoch 154, training accuracy 0.34375\n",
      "time 1769.5134115219116, epoch 155, training accuracy 0.5625\n",
      "time 1780.9016947746277, epoch 156, training accuracy 0.59375\n",
      "time 1792.3655025959015, epoch 157, training accuracy 0.5\n",
      "time 1803.8159210681915, epoch 158, training accuracy 0.59375\n",
      "time 1815.1546585559845, epoch 159, training accuracy 0.6875\n",
      "time 1826.603935956955, epoch 160, training accuracy 0.59375\n",
      "time 1837.8785412311554, epoch 161, training accuracy 0.625\n",
      "time 1849.3964672088623, epoch 162, training accuracy 0.4375\n",
      "time 1860.803867340088, epoch 163, training accuracy 0.53125\n",
      "time 1872.301419019699, epoch 164, training accuracy 0.625\n",
      "time 1883.767107963562, epoch 165, training accuracy 0.71875\n",
      "time 1895.1332569122314, epoch 166, training accuracy 0.46875\n",
      "time 1906.5740814208984, epoch 167, training accuracy 0.46875\n",
      "time 1918.0437071323395, epoch 168, training accuracy 0.59375\n",
      "time 1929.4920511245728, epoch 169, training accuracy 0.6875\n",
      "time 1940.8050246238708, epoch 170, training accuracy 0.625\n",
      "time 1952.1152811050415, epoch 171, training accuracy 0.5\n",
      "time 1963.535521030426, epoch 172, training accuracy 0.59375\n",
      "time 1974.9754884243011, epoch 173, training accuracy 0.625\n",
      "time 1986.4824113845825, epoch 174, training accuracy 0.75\n",
      "time 1997.8844344615936, epoch 175, training accuracy 0.71875\n",
      "time 2009.3074996471405, epoch 176, training accuracy 0.59375\n",
      "time 2020.676346063614, epoch 177, training accuracy 0.625\n",
      "time 2032.0605854988098, epoch 178, training accuracy 0.53125\n",
      "time 2043.5022265911102, epoch 179, training accuracy 0.65625\n",
      "time 2055.0467100143433, epoch 180, training accuracy 0.625\n",
      "time 2066.4262611865997, epoch 181, training accuracy 0.53125\n",
      "time 2077.8384680747986, epoch 182, training accuracy 0.78125\n",
      "time 2089.222603559494, epoch 183, training accuracy 0.65625\n",
      "time 2100.687208175659, epoch 184, training accuracy 0.625\n",
      "time 2112.092099905014, epoch 185, training accuracy 0.6875\n",
      "time 2123.565022945404, epoch 186, training accuracy 0.6875\n",
      "time 2135.1108713150024, epoch 187, training accuracy 0.5\n",
      "time 2146.8282980918884, epoch 188, training accuracy 0.6875\n",
      "time 2158.4069278240204, epoch 189, training accuracy 0.625\n",
      "time 2169.8364400863647, epoch 190, training accuracy 0.6875\n",
      "time 2181.3291749954224, epoch 191, training accuracy 0.625\n",
      "time 2192.803504705429, epoch 192, training accuracy 0.625\n",
      "time 2204.1746871471405, epoch 193, training accuracy 0.75\n",
      "time 2215.6399631500244, epoch 194, training accuracy 0.59375\n",
      "time 2227.1341013908386, epoch 195, training accuracy 0.59375\n",
      "time 2238.5396766662598, epoch 196, training accuracy 0.5\n",
      "time 2250.008224964142, epoch 197, training accuracy 0.625\n",
      "time 2261.4267013072968, epoch 198, training accuracy 0.65625\n",
      "time 2272.8494045734406, epoch 199, training accuracy 0.53125\n",
      "time 2284.250780105591, epoch 200, training accuracy 0.5625\n",
      "time 2295.708168745041, epoch 201, training accuracy 0.53125\n",
      "time 2307.210120201111, epoch 202, training accuracy 0.53125\n",
      "time 2318.6925637722015, epoch 203, training accuracy 0.75\n",
      "time 2330.0852031707764, epoch 204, training accuracy 0.6875\n",
      "time 2341.671763420105, epoch 205, training accuracy 0.6875\n",
      "time 2353.405294895172, epoch 206, training accuracy 0.46875\n",
      "time 2364.9163014888763, epoch 207, training accuracy 0.65625\n",
      "time 2376.398915052414, epoch 208, training accuracy 0.53125\n",
      "time 2387.8701786994934, epoch 209, training accuracy 0.65625\n",
      "time 2399.2113003730774, epoch 210, training accuracy 0.53125\n",
      "time 2410.7122848033905, epoch 211, training accuracy 0.53125\n",
      "time 2422.186980009079, epoch 212, training accuracy 0.71875\n",
      "time 2433.6766374111176, epoch 213, training accuracy 0.59375\n",
      "time 2445.209322452545, epoch 214, training accuracy 0.53125\n",
      "time 2456.825844526291, epoch 215, training accuracy 0.53125\n",
      "time 2468.2277376651764, epoch 216, training accuracy 0.53125\n",
      "time 2479.6876680850983, epoch 217, training accuracy 0.5\n",
      "time 2491.0772058963776, epoch 218, training accuracy 0.625\n",
      "time 2502.5823476314545, epoch 219, training accuracy 0.65625\n",
      "time 2513.958254814148, epoch 220, training accuracy 0.5625\n",
      "time 2525.373384952545, epoch 221, training accuracy 0.5625\n",
      "time 2536.9073679447174, epoch 222, training accuracy 0.625\n",
      "time 2548.274034023285, epoch 223, training accuracy 0.4375\n",
      "time 2559.7001326084137, epoch 224, training accuracy 0.65625\n",
      "time 2571.06183385849, epoch 225, training accuracy 0.59375\n",
      "time 2582.4754440784454, epoch 226, training accuracy 0.5625\n",
      "time 2593.9207334518433, epoch 227, training accuracy 0.6875\n",
      "time 2605.325647354126, epoch 228, training accuracy 0.65625\n",
      "time 2616.826938867569, epoch 229, training accuracy 0.5\n",
      "time 2628.305017232895, epoch 230, training accuracy 0.75\n",
      "time 2639.6660706996918, epoch 231, training accuracy 0.71875\n",
      "time 2650.98873090744, epoch 232, training accuracy 0.5625\n",
      "time 2662.478972196579, epoch 233, training accuracy 0.6875\n",
      "time 2673.932779312134, epoch 234, training accuracy 0.46875\n",
      "time 2685.330067873001, epoch 235, training accuracy 0.625\n",
      "time 2696.7410666942596, epoch 236, training accuracy 0.46875\n",
      "time 2708.138263463974, epoch 237, training accuracy 0.5625\n",
      "time 2719.530271053314, epoch 238, training accuracy 0.53125\n",
      "time 2730.972020626068, epoch 239, training accuracy 0.59375\n",
      "time 2742.41659617424, epoch 240, training accuracy 0.65625\n",
      "time 2753.8914771080017, epoch 241, training accuracy 0.75\n",
      "time 2765.3704097270966, epoch 242, training accuracy 0.625\n",
      "time 2776.7832412719727, epoch 243, training accuracy 0.6875\n",
      "time 2788.2116887569427, epoch 244, training accuracy 0.6875\n",
      "time 2799.6695652008057, epoch 245, training accuracy 0.5625\n",
      "time 2811.196470975876, epoch 246, training accuracy 0.5625\n",
      "time 2822.651353120804, epoch 247, training accuracy 0.625\n",
      "time 2834.166755914688, epoch 248, training accuracy 0.59375\n",
      "time 2845.6039946079254, epoch 249, training accuracy 0.65625\n",
      "time 2857.1408429145813, epoch 250, training accuracy 0.5\n",
      "time 2868.547358751297, epoch 251, training accuracy 0.46875\n",
      "time 2879.909712791443, epoch 252, training accuracy 0.5\n",
      "time 2891.321812391281, epoch 253, training accuracy 0.625\n",
      "time 2902.791084766388, epoch 254, training accuracy 0.46875\n",
      "time 2914.1980481147766, epoch 255, training accuracy 0.53125\n",
      "time 2925.6038703918457, epoch 256, training accuracy 0.75\n",
      "time 2937.0082201957703, epoch 257, training accuracy 0.65625\n",
      "time 2948.5081889629364, epoch 258, training accuracy 0.59375\n",
      "time 2959.892462491989, epoch 259, training accuracy 0.65625\n",
      "time 2971.245403766632, epoch 260, training accuracy 0.625\n",
      "time 2982.673269033432, epoch 261, training accuracy 0.71875\n",
      "time 2994.064971923828, epoch 262, training accuracy 0.5625\n",
      "time 3005.4771118164062, epoch 263, training accuracy 0.65625\n",
      "time 3016.943728685379, epoch 264, training accuracy 0.6875\n",
      "time 3028.4841768741608, epoch 265, training accuracy 0.625\n",
      "time 3039.9411697387695, epoch 266, training accuracy 0.5625\n",
      "time 3051.381032705307, epoch 267, training accuracy 0.65625\n",
      "time 3062.8247485160828, epoch 268, training accuracy 0.5625\n",
      "time 3074.223072052002, epoch 269, training accuracy 0.59375\n",
      "time 3085.6814818382263, epoch 270, training accuracy 0.75\n",
      "time 3097.116699695587, epoch 271, training accuracy 0.65625\n",
      "time 3108.585196495056, epoch 272, training accuracy 0.625\n",
      "time 3119.9635400772095, epoch 273, training accuracy 0.59375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 3131.4493613243103, epoch 274, training accuracy 0.75\n",
      "time 3142.8611516952515, epoch 275, training accuracy 0.71875\n",
      "time 3154.2347917556763, epoch 276, training accuracy 0.5625\n",
      "time 3165.798013687134, epoch 277, training accuracy 0.375\n",
      "time 3177.218919277191, epoch 278, training accuracy 0.59375\n",
      "time 3188.591910123825, epoch 279, training accuracy 0.59375\n",
      "time 3199.9041063785553, epoch 280, training accuracy 0.5625\n",
      "time 3211.4611434936523, epoch 281, training accuracy 0.5625\n",
      "time 3222.8993656635284, epoch 282, training accuracy 0.53125\n",
      "time 3234.303685903549, epoch 283, training accuracy 0.53125\n",
      "time 3245.794689655304, epoch 284, training accuracy 0.65625\n",
      "time 3257.315860271454, epoch 285, training accuracy 0.59375\n",
      "time 3268.7815442085266, epoch 286, training accuracy 0.625\n",
      "time 3280.3579382896423, epoch 287, training accuracy 0.65625\n",
      "time 3291.805622816086, epoch 288, training accuracy 0.5\n",
      "time 3303.2761204242706, epoch 289, training accuracy 0.59375\n",
      "time 3314.5806596279144, epoch 290, training accuracy 0.40625\n",
      "time 3325.9659481048584, epoch 291, training accuracy 0.5625\n",
      "time 3337.414434194565, epoch 292, training accuracy 0.6875\n",
      "time 3349.133740901947, epoch 293, training accuracy 0.71875\n",
      "time 3360.7207205295563, epoch 294, training accuracy 0.65625\n",
      "time 3372.228389263153, epoch 295, training accuracy 0.625\n",
      "time 3383.821125984192, epoch 296, training accuracy 0.71875\n",
      "time 3395.2509438991547, epoch 297, training accuracy 0.6875\n",
      "time 3406.757373571396, epoch 298, training accuracy 0.65625\n",
      "time 3418.2247643470764, epoch 299, training accuracy 0.625\n",
      "time 3429.591682434082, epoch 300, training accuracy 0.65625\n",
      "time 3441.0577659606934, epoch 301, training accuracy 0.6875\n",
      "time 3452.4773037433624, epoch 302, training accuracy 0.625\n",
      "time 3463.9634482860565, epoch 303, training accuracy 0.59375\n",
      "time 3475.463440656662, epoch 304, training accuracy 0.5625\n",
      "time 3486.9659729003906, epoch 305, training accuracy 0.6875\n",
      "time 3498.339579343796, epoch 306, training accuracy 0.6875\n",
      "time 3509.833396911621, epoch 307, training accuracy 0.5\n",
      "time 3521.381640434265, epoch 308, training accuracy 0.53125\n",
      "time 3532.945982694626, epoch 309, training accuracy 0.53125\n",
      "time 3544.394852876663, epoch 310, training accuracy 0.5625\n",
      "time 3555.7442483901978, epoch 311, training accuracy 0.5625\n",
      "time 3567.2672357559204, epoch 312, training accuracy 0.5625\n",
      "time 3578.6945757865906, epoch 313, training accuracy 0.59375\n",
      "time 3590.0796909332275, epoch 314, training accuracy 0.65625\n",
      "time 3601.503133535385, epoch 315, training accuracy 0.59375\n",
      "time 3613.0359263420105, epoch 316, training accuracy 0.6875\n",
      "time 3624.4649901390076, epoch 317, training accuracy 0.53125\n",
      "time 3635.9669950008392, epoch 318, training accuracy 0.59375\n",
      "time 3647.3697271347046, epoch 319, training accuracy 0.5625\n",
      "time 3658.752876996994, epoch 320, training accuracy 0.625\n",
      "time 3670.1708743572235, epoch 321, training accuracy 0.5625\n",
      "time 3681.6664900779724, epoch 322, training accuracy 0.59375\n",
      "time 3693.1271414756775, epoch 323, training accuracy 0.59375\n",
      "time 3704.623879432678, epoch 324, training accuracy 0.46875\n",
      "time 3716.098305463791, epoch 325, training accuracy 0.5625\n",
      "time 3727.5681653022766, epoch 326, training accuracy 0.625\n",
      "time 3739.0457820892334, epoch 327, training accuracy 0.71875\n",
      "time 3750.388243675232, epoch 328, training accuracy 0.53125\n",
      "time 3761.7579112052917, epoch 329, training accuracy 0.5625\n",
      "time 3773.30868768692, epoch 330, training accuracy 0.5625\n",
      "time 3784.9158878326416, epoch 331, training accuracy 0.5\n",
      "time 3796.244521856308, epoch 332, training accuracy 0.4375\n",
      "time 3807.669213294983, epoch 333, training accuracy 0.65625\n",
      "time 3819.0167899131775, epoch 334, training accuracy 0.53125\n",
      "time 3830.4213151931763, epoch 335, training accuracy 0.5\n",
      "time 3841.8750755786896, epoch 336, training accuracy 0.65625\n",
      "time 3853.3339314460754, epoch 337, training accuracy 0.59375\n",
      "time 3864.836242198944, epoch 338, training accuracy 0.6875\n",
      "time 3876.3087661266327, epoch 339, training accuracy 0.625\n",
      "time 3887.6768803596497, epoch 340, training accuracy 0.71875\n",
      "time 3899.209604024887, epoch 341, training accuracy 0.65625\n",
      "time 3910.6966848373413, epoch 342, training accuracy 0.6875\n",
      "time 3922.1853034496307, epoch 343, training accuracy 0.59375\n",
      "time 3933.5740134716034, epoch 344, training accuracy 0.65625\n",
      "time 3945.0472877025604, epoch 345, training accuracy 0.75\n",
      "time 3956.3831503391266, epoch 346, training accuracy 0.625\n",
      "time 3967.783644914627, epoch 347, training accuracy 0.5625\n",
      "time 3979.1788136959076, epoch 348, training accuracy 0.75\n",
      "time 3990.542090654373, epoch 349, training accuracy 0.5625\n",
      "time 4002.01548576355, epoch 350, training accuracy 0.53125\n",
      "time 4013.4319863319397, epoch 351, training accuracy 0.5625\n",
      "time 4024.7302231788635, epoch 352, training accuracy 0.59375\n",
      "time 4036.210741519928, epoch 353, training accuracy 0.6875\n",
      "time 4047.5683917999268, epoch 354, training accuracy 0.46875\n",
      "time 4058.962213039398, epoch 355, training accuracy 0.6875\n",
      "time 4070.3970005512238, epoch 356, training accuracy 0.65625\n",
      "time 4081.791045188904, epoch 357, training accuracy 0.65625\n",
      "time 4093.2126564979553, epoch 358, training accuracy 0.75\n",
      "time 4104.626216650009, epoch 359, training accuracy 0.625\n",
      "time 4116.025418519974, epoch 360, training accuracy 0.5625\n",
      "time 4127.48486995697, epoch 361, training accuracy 0.65625\n",
      "time 4138.7799208164215, epoch 362, training accuracy 0.53125\n",
      "time 4150.139295339584, epoch 363, training accuracy 0.375\n",
      "time 4161.569963693619, epoch 364, training accuracy 0.71875\n",
      "time 4172.977524995804, epoch 365, training accuracy 0.5625\n",
      "time 4184.370423316956, epoch 366, training accuracy 0.59375\n",
      "time 4195.737370729446, epoch 367, training accuracy 0.6875\n",
      "time 4207.116528272629, epoch 368, training accuracy 0.5\n",
      "time 4218.556938648224, epoch 369, training accuracy 0.53125\n",
      "time 4230.018369674683, epoch 370, training accuracy 0.59375\n",
      "time 4241.362370252609, epoch 371, training accuracy 0.71875\n",
      "time 4252.704454898834, epoch 372, training accuracy 0.6875\n",
      "time 4264.116057634354, epoch 373, training accuracy 0.375\n",
      "time 4275.517117738724, epoch 374, training accuracy 0.53125\n",
      "time 4287.036011457443, epoch 375, training accuracy 0.5\n",
      "time 4298.381864070892, epoch 376, training accuracy 0.5\n",
      "time 4309.689815044403, epoch 377, training accuracy 0.6875\n",
      "time 4320.966428279877, epoch 378, training accuracy 0.53125\n",
      "time 4332.388242959976, epoch 379, training accuracy 0.53125\n",
      "time 4343.808462142944, epoch 380, training accuracy 0.78125\n",
      "time 4355.301663398743, epoch 381, training accuracy 0.5\n",
      "time 4366.655188798904, epoch 382, training accuracy 0.5\n",
      "time 4378.059508800507, epoch 383, training accuracy 0.71875\n",
      "time 4389.442229986191, epoch 384, training accuracy 0.59375\n",
      "time 4400.766426563263, epoch 385, training accuracy 0.65625\n",
      "time 4412.2789142131805, epoch 386, training accuracy 0.8125\n",
      "time 4423.699462652206, epoch 387, training accuracy 0.5625\n",
      "time 4435.132023334503, epoch 388, training accuracy 0.65625\n",
      "time 4446.457893610001, epoch 389, training accuracy 0.71875\n",
      "time 4457.798458576202, epoch 390, training accuracy 0.625\n",
      "time 4469.201406240463, epoch 391, training accuracy 0.625\n",
      "time 4480.577512264252, epoch 392, training accuracy 0.65625\n",
      "time 4491.978000879288, epoch 393, training accuracy 0.65625\n",
      "time 4503.462262392044, epoch 394, training accuracy 0.5\n",
      "time 4514.760798692703, epoch 395, training accuracy 0.75\n",
      "time 4526.131257534027, epoch 396, training accuracy 0.5625\n",
      "time 4537.51266169548, epoch 397, training accuracy 0.5\n",
      "time 4548.935722112656, epoch 398, training accuracy 0.59375\n",
      "time 4560.26457285881, epoch 399, training accuracy 0.625\n",
      "time 4571.583616256714, epoch 400, training accuracy 0.5625\n",
      "time 4582.914417266846, epoch 401, training accuracy 0.65625\n",
      "time 4594.249660491943, epoch 402, training accuracy 0.59375\n",
      "time 4605.619512557983, epoch 403, training accuracy 0.53125\n",
      "time 4617.019943714142, epoch 404, training accuracy 0.6875\n",
      "time 4628.414876937866, epoch 405, training accuracy 0.46875\n",
      "time 4639.816749095917, epoch 406, training accuracy 0.53125\n",
      "time 4651.200991630554, epoch 407, training accuracy 0.5625\n",
      "time 4662.6814177036285, epoch 408, training accuracy 0.53125\n",
      "time 4674.184432268143, epoch 409, training accuracy 0.53125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 4685.551441669464, epoch 410, training accuracy 0.625\n",
      "time 4696.933883905411, epoch 411, training accuracy 0.59375\n",
      "time 4708.341626167297, epoch 412, training accuracy 0.65625\n",
      "time 4719.702955961227, epoch 413, training accuracy 0.625\n",
      "time 4731.134139060974, epoch 414, training accuracy 0.53125\n",
      "time 4742.55773639679, epoch 415, training accuracy 0.625\n",
      "time 4754.153601646423, epoch 416, training accuracy 0.5625\n",
      "time 4765.823804616928, epoch 417, training accuracy 0.65625\n",
      "time 4777.567023992538, epoch 418, training accuracy 0.65625\n",
      "time 4789.292713880539, epoch 419, training accuracy 0.625\n",
      "time 4800.71041727066, epoch 420, training accuracy 0.5625\n",
      "time 4812.325362920761, epoch 421, training accuracy 0.71875\n",
      "time 4824.1120002269745, epoch 422, training accuracy 0.6875\n",
      "time 4835.791969060898, epoch 423, training accuracy 0.59375\n",
      "time 4848.466763973236, epoch 424, training accuracy 0.5625\n",
      "time 4860.570207118988, epoch 425, training accuracy 0.65625\n",
      "time 4872.290109872818, epoch 426, training accuracy 0.75\n",
      "time 4884.196662187576, epoch 427, training accuracy 0.59375\n",
      "time 4895.725014925003, epoch 428, training accuracy 0.625\n",
      "time 4907.475213527679, epoch 429, training accuracy 0.53125\n",
      "time 4919.061797857285, epoch 430, training accuracy 0.59375\n",
      "time 4930.769588708878, epoch 431, training accuracy 0.53125\n",
      "time 4942.341194391251, epoch 432, training accuracy 0.65625\n",
      "time 4953.9482617378235, epoch 433, training accuracy 0.625\n",
      "time 4965.5711171627045, epoch 434, training accuracy 0.65625\n",
      "time 4977.281986713409, epoch 435, training accuracy 0.5\n",
      "time 4988.914357662201, epoch 436, training accuracy 0.53125\n",
      "time 5000.7236177921295, epoch 437, training accuracy 0.5\n",
      "time 5012.307626724243, epoch 438, training accuracy 0.6875\n",
      "time 5023.856716156006, epoch 439, training accuracy 0.65625\n",
      "time 5035.702720403671, epoch 440, training accuracy 0.65625\n",
      "time 5047.541975736618, epoch 441, training accuracy 0.65625\n",
      "time 5059.323116540909, epoch 442, training accuracy 0.53125\n",
      "time 5071.323083400726, epoch 443, training accuracy 0.71875\n",
      "time 5083.534479856491, epoch 444, training accuracy 0.6875\n",
      "time 5095.447411775589, epoch 445, training accuracy 0.625\n",
      "time 5107.4991846084595, epoch 446, training accuracy 0.625\n",
      "time 5119.418264865875, epoch 447, training accuracy 0.53125\n",
      "time 5131.017271995544, epoch 448, training accuracy 0.59375\n",
      "time 5142.814377069473, epoch 449, training accuracy 0.5625\n",
      "time 5154.545928239822, epoch 450, training accuracy 0.5\n",
      "time 5166.118796348572, epoch 451, training accuracy 0.53125\n",
      "time 5178.14288020134, epoch 452, training accuracy 0.78125\n",
      "time 5189.9870817661285, epoch 453, training accuracy 0.6875\n",
      "time 5201.842540740967, epoch 454, training accuracy 0.5625\n",
      "time 5213.638859033585, epoch 455, training accuracy 0.53125\n",
      "time 5225.360808372498, epoch 456, training accuracy 0.75\n",
      "time 5237.066216945648, epoch 457, training accuracy 0.59375\n",
      "time 5248.976871013641, epoch 458, training accuracy 0.71875\n",
      "time 5260.9588534832, epoch 459, training accuracy 0.71875\n",
      "time 5272.924805879593, epoch 460, training accuracy 0.71875\n",
      "time 5284.519912004471, epoch 461, training accuracy 0.625\n",
      "time 5295.980459213257, epoch 462, training accuracy 0.53125\n",
      "time 5307.51402258873, epoch 463, training accuracy 0.5625\n",
      "time 5319.084374427795, epoch 464, training accuracy 0.5625\n",
      "time 5330.58095574379, epoch 465, training accuracy 0.53125\n",
      "time 5342.09766626358, epoch 466, training accuracy 0.71875\n",
      "time 5353.916300296783, epoch 467, training accuracy 0.71875\n",
      "time 5365.980079174042, epoch 468, training accuracy 0.59375\n",
      "time 5377.90370965004, epoch 469, training accuracy 0.5\n",
      "time 5389.705715179443, epoch 470, training accuracy 0.59375\n",
      "time 5401.3412754535675, epoch 471, training accuracy 0.625\n",
      "time 5413.222022294998, epoch 472, training accuracy 0.5\n",
      "time 5424.9372527599335, epoch 473, training accuracy 0.71875\n",
      "time 5436.653684616089, epoch 474, training accuracy 0.65625\n",
      "time 5448.454270362854, epoch 475, training accuracy 0.625\n",
      "time 5460.1130385398865, epoch 476, training accuracy 0.59375\n",
      "time 5471.932240962982, epoch 477, training accuracy 0.71875\n",
      "time 5483.483407258987, epoch 478, training accuracy 0.65625\n",
      "time 5495.103271722794, epoch 479, training accuracy 0.5625\n",
      "time 5506.81435585022, epoch 480, training accuracy 0.65625\n",
      "time 5518.609878778458, epoch 481, training accuracy 0.65625\n",
      "time 5530.936058282852, epoch 482, training accuracy 0.5625\n",
      "time 5542.781074762344, epoch 483, training accuracy 0.625\n",
      "time 5554.648769378662, epoch 484, training accuracy 0.65625\n",
      "time 5566.324861764908, epoch 485, training accuracy 0.5\n",
      "time 5578.050346851349, epoch 486, training accuracy 0.5\n",
      "time 5589.8950300216675, epoch 487, training accuracy 0.59375\n",
      "time 5601.734949588776, epoch 488, training accuracy 0.4375\n",
      "time 5613.8974776268005, epoch 489, training accuracy 0.53125\n",
      "time 5625.561478853226, epoch 490, training accuracy 0.59375\n",
      "time 5637.040811061859, epoch 491, training accuracy 0.5625\n",
      "time 5648.647943973541, epoch 492, training accuracy 0.75\n",
      "time 5660.292901754379, epoch 493, training accuracy 0.5625\n",
      "time 5672.399743080139, epoch 494, training accuracy 0.59375\n",
      "time 5684.148138999939, epoch 495, training accuracy 0.71875\n",
      "time 5695.9974801540375, epoch 496, training accuracy 0.6875\n",
      "time 5707.818527698517, epoch 497, training accuracy 0.4375\n",
      "time 5719.567648410797, epoch 498, training accuracy 0.53125\n",
      "time 5731.667359113693, epoch 499, training accuracy 0.59375\n",
      "test accuracy: 0.621999979019165\n"
     ]
    }
   ],
   "source": [
    " with tf.device(\"/gpu:0\"):   \n",
    "    with tf.Session() as sess: \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for j in range(EPOCH_NUM):\n",
    "            for i in range(SAMPLES_PER_EPOCH // BATCH_SIZE):\n",
    "                batch_trainf, batch_trainl = get_batch(train_features,train_labels,BATCH_SIZE)\n",
    "                sess.run(train_step , feed_dict={x: batch_trainf, y_: batch_trainl, keep_prob: 0.5}) \n",
    "            batch_trainf, batch_trainl = get_batch(test_features,test_labels,32)\n",
    "            train_accuracy = sess.run(accuracy , feed_dict={x: batch_trainf, y_: batch_trainl, keep_prob: 1.0}) \n",
    "            print(\"time {}, epoch {}, training accuracy {}\".format(time.time() - start_time, j, train_accuracy)) \n",
    "\n",
    "        test_accuracy = np.mean([sess.run(accuracy , feed_dict={x:test_features, y_:test_labels, keep_prob:1.0})])\n",
    "        print(\"test accuracy: {}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
